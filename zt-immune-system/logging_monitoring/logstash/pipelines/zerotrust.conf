# logstash/pipelines/zerotrust.conf
# Logstash pipeline for processing ZeroTrust Immune System logs

input {
  # Example: Beat input for Filebeat/Winlogbeat shippers from agents/servers
  beats {
    port => 5044
    # ssl => true
    # ssl_certificate => "/etc/logstash/certs/logstash.crt"
    # ssl_key => "/etc/logstash/certs/logstash.key"
    # ssl_certificate_authorities => ["/etc/logstash/certs/ca.crt"]
    # ssl_verify_mode => "force_peer" # or "peer" if clients might not have certs
  }

  # Example: Kafka input for logs from IA Principale or other components
  # kafka {
  #   bootstrap_servers => "kafka_server:9092"
  #   topics => ["zt_app_logs", "zt_security_events"]
  #   group_id => "logstash_zerotrust_pipeline"
  #   codec => "json" # Assuming logs from Kafka are in JSON format
  # }

  # Example: Syslog input
  # syslog {
  #   port => 5140
  #   type => "syslog" # Adds a 'type' field
  # }
}

filter {
  # Apply common mutations or parsing first
  if [message] {
    # Attempt to parse JSON if the message is a JSON string
    # json {
    #   source => "message"
    #   target => "json_payload" # Put parsed JSON into a target field
    #   # remove_field => ["message"] # Optionally remove original message if successfully parsed
    # }
  }

  # --- PII (Personally Identifiable Information) Suppression ---
  # This is highly dependent on the structure of your logs and what constitutes PII.
  # Example: Anonymize IP addresses in a specific field (e.g., client.ip)
  # if [json_payload][client][ip] {
  #   anonymize {
  #     fields => ["[json_payload][client][ip]"]
  #     algorithm => "SHA256" # Or "SHA1", "MD5", or "static" for replacement
  #     # key => "your_secret_salt" # For HMAC based algorithms
  #   }
  # }
  # Example: Mutate to remove or mask a field containing sensitive data
  # if [json_payload][user][credit_card_number] {
  #   mutate {
  #     remove_field => ["[json_payload][user][credit_card_number]"]
  #     # Or replace with a masked value:
  #     # replace => { "[json_payload][user][credit_card_number]" => "REDACTED_CC" }
  #   }
  # }
  # Note: PII stripping should be done carefully and tested thoroughly.
  # Consider legal and compliance requirements. Using Logstash for PII removal
  # means Logstash itself will see the PII briefly.

  # --- Grok Parsing for unstructured logs (if not JSON or already parsed by Filebeat) ---
  # if [type] == "syslog" or [event][dataset] == "my_custom_app.log" {
  #   grok {
  #     match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} %{HOSTNAME:hostname} %{PROG:program}(?:\[%{POSINT:pid}\])?: %{GREEDYDATA:logmessage}" }
  #     # patterns_dir => ["/usr/share/logstash/patterns"] # Default, or path to your custom patterns
  #     # patterns_files_glob => "grok-patterns" # If using custom patterns file from patterns/ directory
  #     # add_field => { "parsed_by_grok" => "true" }
  #   }
  # }

  # --- Date Parsing (if @timestamp is not correctly set by input or grok) ---
  # if ![timestamp] and [log_timestamp_field] {
  #    date {
  #      match => [ "log_timestamp_field", "ISO8601", "yyyy-MM-dd HH:mm:ss,SSS" ]
  #      target => "@timestamp"
  #    }
  # }


  # --- GeoIP Enrichment for source and destination IPs ---
  # Requires GeoLite2-City.mmdb or similar database.
  # if [source][ip] {
  #   geoip {
  #     source => "[source][ip]"
  #     target => "[source][geo]"
  #     # database => "/path/to/GeoLite2-City.mmdb"
  #     # fields => ["city_name", "country_name", "country_code2", "continent_name", "location"]
  #     # add_tag => ["geoip_source_enriched"]
  #   }
  # }
  # if [destination][ip] {
  #   geoip {
  #     source => "[destination][ip]"
  #     target => "[destination][geo]"
  #     # add_tag => ["geoip_destination_enriched"]
  #   }
  # }

  # --- IOC (Indicator of Compromise) Enrichment ---
  # This section would typically involve checking fields against known IOC lists.
  # This could be done via:
  # 1. Translate filter with a dictionary file of IOCs.
  # 2. Elasticsearch filter to query an IOC index.
  # 3. HTTP filter to call an external threat intelligence API.

  # Example using translate filter (for smaller, local IOC lists):
  # Assume you have a CSV file `iocs.csv` with `ioc_value,ioc_type,threat_level`
  # dictionary_path => "/path/to/your/iocs_translate_map.yaml"
  # if [source][ip] {
  #   translate {
  #     field => "[source][ip]"
  #     destination => "[threat_intel][source_ip_match]"
  #     dictionary_path => "/etc/logstash/dictionaries/ip_iocs.yaml" # Example path
  #     fallback => "no_match"
  #     # add_tag => "ioc_ip_lookup"
  #   }
  # }
  # if [file][hash][sha256] {
  #   translate {
  #     field => "[file][hash][sha256]"
  #     destination => "[threat_intel][file_hash_match]"
  #     dictionary_path => "/etc/logstash/dictionaries/hash_iocs.yaml" # Example path
  #     # add_tag => "ioc_hash_lookup"
  #   }
  # }
  # if [threat_intel] { # If any IOC match occurred
  #   mutate {
  #     add_tag => "ioc_detected"
  #   }
  #   # You might want to copy the matched IOC details into a structured field.
  # }

  # --- Standardize ECS (Elastic Common Schema) fields if not already done ---
  # This ensures consistency for Kibana dashboards and Elasticsearch queries.
  # Example: if [program] and ![process][name] { mutate { rename => { "program" => "[process][name]" } } }
  # if [hostname] and ![host][name] { mutate { rename => { "hostname" => "[host][name]" } } }

  # Clean up unnecessary fields
  # mutate {
  #   remove_field => ["json_payload"] # If original JSON was parsed into root or other fields
  # }
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "zt-logs-%{+YYYY.MM.dd}" # Daily indices, managed by ILM via alias
    # manage_template => false # Assuming template is managed externally (e.g., via Elasticsearch API directly)
    # template_name => "zt_index_template_name" # If manage_template is true
    # ilm_rollover_alias => "zt-logs-alias" # Alias for ILM
    # ilm_policy => "zt_ilm_policy_name"   # ILM policy name
    # user => "logstash_writer"
    # password => "password"
  }

  # For debugging purposes:
  # stdout { codec => rubydebug }
}
